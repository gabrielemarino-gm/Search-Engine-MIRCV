TODO LIST
1. Il preprocesser deve solo preprocessare testo, lo split per docid, text va fatto PRIMA
2. Nel preprocesser, il lowerCase va fatto dopo aver controllato che non ci siano parole attaccate
    ie. CiaoSono Matteo -> Ciao Sono Matteo

3. Merging dei blocchi
4. Migliorare inverted index
5. Il Vocabolario va creato al momento del merging
    Durante la creazione dell inverted index, va creata la DocumentIndex
6. Creare il document index
7. Se vogliamo confrontare Java/C++












# -----------------------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------------------

# Preprocessing poi SPIMI (Documento per documento) - Preprocessing dentro SPIMI oppure Preprocessing prima di darlo a SPIMI?
# Inverse Index Creation
#   -   Inverse Index Structure
#   -   Lexicon (Terms info)
#   -   Document Table (Document info [metadati in general])

# 2. Come si controlla la memoria libera/occupata (RAM)

#import psutil

# Ottieni le informazioni sull'uso della memoria RAM
#mem = psutil.virtual_memory()

# Stampa le informazioni sull'uso della memoria RAM
# print(f"Memoria totale: {mem.total} bytes")
# print(f"Memoria disponibile: {mem.available / (1024 ** 2)} megabytes")
# print(f"Memoria in uso: {mem.used / (1024 ** 3)} gigabytes")
# print(f"Percentuale di utilizzo della memoria: {mem.percent}%")

# Pseudocode SPIMI (Single-Pass In-Memory Indexing)
# C'è una parte dell'algoritmo omessa: qualla che fa il parse dei documenti,
# e li trasforma nella coppia (Term, DocID) = token SPIMI va chiamato a loop per i vari token_strem
#
# SPIMI-INVERT(token_stream) Token = É una coppia Term-DocID

#     output file = NEWFILE()
#     dictionary = NEWHASH()
#     while (free memory available)
#     do token <— next(token_stream)
#         if term(token) NOT IN dictionary
#             then postings_list = ADDToDICTIONARY (dictionary, term(token))
#         else postings_list = GETPosTIngsLIsT(dictionary, term(token))
#         if full (postings_list)
#             then postings_list = DoUbLEPostINgsLIsT (dictionary, term(token))
#         ADDToPosTINgsLIsT (postings list, doclD(token))
#     sorted terms <— SORTTerMs(dictionary)
#     WRITE-BLOCKToDIsk(sorted_terms, dictionary, output file)
#     return output_file


# ----------------GLI APPUNTI DI MATTE----------------
# SPIMI -> Utilizza le classi InvertedIndex, Vucabulary e Preprocesser per applicare l'algoritmo

# Inizializzazione -> Prende in input il file da processare e in output dove mettere indici parziali/finali
# Una volta inizializzato tutto, la funzione algorithm() inizia a fare cose
# Gestione della memoria delegata a SPIMI

# Scrittura e lettura degli indici parziali/finali, la fa SPIMI o viene delegata alla classe InvertedIndex?
# Prima  o poi qualcuno dovra ciclare la lista di parole per ogni riga(documento), lo fa SPIMI